{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvertPrinttoText.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGwS/CBMGlwzh3oBDnixdp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelogeomac/convet_print_to_text/blob/main/ConvertPrinttoText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ybSDVT26dSL",
        "outputId": "193e934b-523e-43c7-d3f8-55da8f44488a"
      },
      "source": [
        "! pip install pillow\n",
        "! pip install pytesseract\n",
        "! pip install imutils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14072 sha256=3af7448281d674c2443419f8b90bde388d2166516f73ca6468981dbc11b26a10\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/89/b9/3f11250225d0f90e5454fcc30fd1b7208db226850715aa9ace\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHpyaQ2k5_-K"
      },
      "source": [
        "from imutils.object_detection import non_max_suppression\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import argparse\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RziAiBFN7m56"
      },
      "source": [
        "# OpenCV and OCR text recognition with Tesseract\n",
        "def decode_predictions(scores, geometry):\n",
        "  # grab the number of rows and columns from the scores volume, then\n",
        "\t# initialize our set of bounding box rectangles and corresponding\n",
        "\t# confidence scores\n",
        "  (num_Rows, num_Cols) = scores.shape[2:4]\n",
        "  rects = []\n",
        "  confidence = []\n",
        "  \n",
        "  # loop over the number of rows\n",
        "  for y in range(0, num_Rows):   # extract the scores (probabilities), followed by the \t# geometrical data used to derive potential bounding box \t# coordinates that surround text\n",
        "   scoresData = scores[0, 0, y]\n",
        "xData0 = geometry[0, 0, y]\n",
        "xData1 = geometry[0, 1, y]\n",
        "xData2 = geometry[0, 2, y]\n",
        "xData3 = geometry[0, 3, y]\n",
        "anglesData = geometry[0, 4, y]\n",
        "\n",
        "\t\t# loop over the number of columns\n",
        "\t\tfor x in range(0, numCols):\n",
        "\t\t\t# if our score does not have sufficient probability,\n",
        "\t\t\t# ignore it\n",
        "\t\t\tif scoresData[x] < args[\"min_confidence\"]:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# compute the offset factor as our resulting feature\n",
        "\t\t\t# maps will be 4x smaller than the input image\n",
        "\t\t\t(offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
        "\t\t\t# extract the rotation angle for the prediction and\n",
        "\t\t\t# then compute the sin and cosine\n",
        "\t\t\tangle = anglesData[x]\n",
        "\t\t\tcos = np.cos(angle)\n",
        "\t\t\tsin = np.sin(angle)\n",
        "\t\t\t# use the geometry volume to derive the width and height\n",
        "\t\t\t# of the bounding box\n",
        "\t\t\th = xData0[x] + xData2[x]\n",
        "\t\t\tw = xData1[x] + xData3[x]\n",
        "\t\t\t# compute both the starting and ending (x, y)-coordinates\n",
        "\t\t\t# for the text prediction bounding box\n",
        "\t\t\tendX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
        "\t\t\tendY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
        "\t\t\tstartX = int(endX - w)\n",
        "\t\t\tstartY = int(endY - h)\n",
        "\t\t\t# add the bounding box coordinates and probability score\n",
        "\t\t\t# to our respective lists\n",
        "\t\t\trects.append((startX, startY, endX, endY))\n",
        "\t\t\tconfidences.append(scoresData[x])\n",
        "\t# return a tuple of the bounding boxes and associated confidences\n",
        "\treturn (rects, confidences)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4TJx1OP_W0l",
        "outputId": "8f424f97-1719-4b37-fd4a-aa09baa9befc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLlRZawWFAIN"
      },
      "source": [
        "# ...\n",
        "import sys\n",
        "sys.argv=['']\n",
        "del sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jbVfgwFAgDo"
      },
      "source": [
        "# construct the argument parser and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\", \"--image\", type=str,\n",
        "\thelp=\"path to input image\")\n",
        "ap.add_argument(\"-east\", \"--east\", type=str,\n",
        "\thelp=\"path to input EAST text detector\")\n",
        "ap.add_argument(\"-c\", \"--min-confidence\", type=float, default=0.5,\n",
        "\thelp=\"minimum probability required to inspect a region\")\n",
        "ap.add_argument(\"-w\", \"--width\", type=int, default=320,\n",
        "\thelp=\"nearest multiple of 32 for resized width\")\n",
        "ap.add_argument(\"-e\", \"--height\", type=int, default=320,\n",
        "\thelp=\"nearest multiple of 32 for resized height\")\n",
        "ap.add_argument(\"-p\", \"--padding\", type=float, default=0.0,\n",
        "\thelp=\"amount of padding to add to each border of ROI\")\n",
        "args = vars(ap.parse_args())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQUe8qmTL3Ra"
      },
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/MSC/Servicos/Dados_teste/images/nota.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "E7ZKTyO1FSTc",
        "outputId": "4f3b0b31-672d-4ad5-f052-bd75dbce2a57"
      },
      "source": [
        "# load the input image and grab the image dimensions\n",
        "imagem = cv2.imread(args[\"/content/drive/MyDrive/MSC/Servicos/Dados_teste/images/nota.jpg\"])\n",
        "orig = image.copy()\n",
        "(origH, origW) = image.shape[:2]\n",
        "# set the new width and height and then determine the ratio in change\n",
        "# for both the width and height\n",
        "(newW, newH) = (args[\"width\"], args[\"height\"])\n",
        "rW = origW / float(newW)\n",
        "rH = origH / float(newH)\n",
        "# resize the image and grab the new image dimensions\n",
        "image = cv2.resize(image, (newW, newH))\n",
        "(H, W) = image.shape[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-0d57590b3c8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the input image and grab the image dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimagem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/MSC/Servicos/Dados_teste/images/nota.jpg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0morigH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# set the new width and height and then determine the ratio in change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '/content/drive/MyDrive/MSC/Servicos/Dados_teste/images/nota.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sk2UJ_-INm3"
      },
      "source": [
        "# define the two output layer names for the EAST detector model that\n",
        "# we are interested in -- the first is the output probabilities and the\n",
        "# second can be used to derive the bounding box coordinates of text\n",
        "layerNames = [\n",
        "\t\"feature_fusion/Conv_7/Sigmoid\",\n",
        "\t\"feature_fusion/concat_3\"]\n",
        "# load the pre-trained EAST text detector\n",
        "print(\"[INFO] loading EAST text detector...\")\n",
        "net = cv2.dnn.readNet(args[\"east\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnCIrkBtMbVY"
      },
      "source": [
        "# construct a blob from the image and then perform a forward pass of\n",
        "# the model to obtain the two output layer sets\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
        "\t(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
        "net.setInput(blob)\n",
        "(scores, geometry) = net.forward(layerNames)\n",
        "# decode the predictions, then  apply non-maxima suppression to\n",
        "# suppress weak, overlapping bounding boxes\n",
        "(rects, confidences) = decode_predictions(scores, geometry)\n",
        "boxes = non_max_suppression(np.array(rects), probs=confidences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqOxiIYuMcXC"
      },
      "source": [
        "# initialize the list of results\n",
        "results = []\n",
        "# loop over the bounding boxes\n",
        "for (startX, startY, endX, endY) in boxes:\n",
        "\t# scale the bounding box coordinates based on the respective\n",
        "\t# ratios\n",
        "\tstartX = int(startX * rW)\n",
        "\tstartY = int(startY * rH)\n",
        "\tendX = int(endX * rW)\n",
        "\tendY = int(endY * rH)\n",
        "\t# in order to obtain a better OCR of the text we can potentially\n",
        "\t# apply a bit of padding surrounding the bounding box -- here we\n",
        "\t# are computing the deltas in both the x and y directions\n",
        "\tdX = int((endX - startX) * args[\"padding\"])\n",
        "\tdY = int((endY - startY) * args[\"padding\"])\n",
        "\t# apply padding to each side of the bounding box, respectively\n",
        "\tstartX = max(0, startX - dX)\n",
        "\tstartY = max(0, startY - dY)\n",
        "\tendX = min(origW, endX + (dX * 2))\n",
        "\tendY = min(origH, endY + (dY * 2))\n",
        "\t# extract the actual padded ROI\n",
        "\troi = orig[startY:endY, startX:endX]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8WRL5RUO8FI"
      },
      "source": [
        "\t# in order to apply Tesseract v4 to OCR text we must supply\n",
        "\t# (1) a language, (2) an OEM flag of 4, indicating that the we\n",
        "\t# wish to use the LSTM neural net model for OCR, and finally\n",
        "\t# (3) an OEM value, in this case, 7 which implies that we are\n",
        "\t# treating the ROI as a single line of text\n",
        "\tconfig = (\"-l eng --oem 1 --psm 7\")\n",
        "\ttext = pytesseract.image_to_string(roi, config=config)\n",
        "\t# add the bounding box coordinates and OCR'd text to the list\n",
        "\t# of results\n",
        "\tresults.append(((startX, startY, endX, endY), text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Meo2Z-SyPB-l"
      },
      "source": [
        "# sort the results bounding box coordinates from top to bottom\n",
        "results = sorted(results, key=lambda r:r[0][1])\n",
        "# loop over the results\n",
        "for ((startX, startY, endX, endY), text) in results:\n",
        "\t# display the text OCR'd by Tesseract\n",
        "\tprint(\"OCR TEXT\")\n",
        "\tprint(\"========\")\n",
        "\tprint(\"{}\\n\".format(text))\n",
        "\t# strip out non-ASCII text so we can draw the text on the image\n",
        "\t# using OpenCV, then draw the text and a bounding box surrounding\n",
        "\t# the text region of the input image\n",
        "\ttext = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
        "\toutput = orig.copy()\n",
        "\tcv2.rectangle(output, (startX, startY), (endX, endY),\n",
        "\t\t(0, 0, 255), 2)\n",
        "\tcv2.putText(output, text, (startX, startY - 20),\n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
        "\t# show the output image\n",
        "\tcv2.imshow(\"Text Detection\", output)\n",
        "\tcv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZtMEyZmPHBG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}